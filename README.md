# Makine Ã–ÄŸrenmesi Dersi 1 - KNN

Bu notebook'ta katÄ±ldÄ±m bootcampten Ã¶ÄŸrendiÄŸim bilgiler Ä±ÅŸÄ±nda ve yaptÄ±ÄŸÄ±mÄ±z pratikleri paylaÅŸacaÄŸÄ±m. Ä°lk olarak gÃ¶zetimli Ã¶pÄŸrenme algoritmalarÄ±ndan sÄ±nÄ±flandÄ±rma kÄ±smÄ±ndan baÅŸlÄ±yorum. Ä°lk algoritmamÄ±z K-En YakÄ±n KomÅŸu (KNN) algoritmaasÄ±. Bu projede iki problem Ã§Ã¶zdÃ¼m: meme kanseri teÅŸhisi ve fonksiyon tahmini.

## ğŸ¯ Ne YaptÄ±m?

### 1. Meme Kanseri TeÅŸhisi
Wisconsin Breast Cancer veri setini kullandÄ±m. 30 farklÄ± Ã¶zellik var (hÃ¼cre Ã§apÄ±, doku kalÄ±nlÄ±ÄŸÄ± gibi). HÃ¼crelerin iyi huylu mu kÃ¶tÃ¼ huylu mu olduÄŸunu tahmin etmeye Ã§alÄ±ÅŸtÄ±m.

### 2. Fonksiyon Tahmini
SinÃ¼s fonksiyonu verisi oluÅŸturdum ve gÃ¼rÃ¼ltÃ¼ ekledim. KNN'in bu gÃ¼rÃ¼ltÃ¼lÃ¼ verilerden orijinal fonksiyonu ne kadar iyi tahmin edebileceÄŸini test ettim.

Ä°ki aÄŸÄ±rlÄ±k stratejisi denedim: Uniform (eÅŸit aÄŸÄ±rlÄ±k) ve Distance (yakÄ±n komÅŸular daha etkili).

## ğŸ› ï¸ KullandÄ±ÄŸÄ±m AraÃ§lar

Python kÃ¼tÃ¼phaneleri: Pandas (veri dÃ¼zenleme), NumPy (hesaplamalar), Scikit-learn (KNN algoritmasÄ±), Matplotlib (gÃ¶rselleÅŸtirme).

## ğŸ“Š SonuÃ§lar

### Meme Kanseri TeÅŸhisi
K=3 ile baÅŸladÄ±m, **%95.9 doÄŸruluk** aldÄ±m. 100 hastadan 96'sÄ±nÄ± doÄŸru teÅŸhis ettim.

**Hata analizi**: Ä°yi huylu 59 doÄŸru, 3 yanlÄ±ÅŸ. KÃ¶tÃ¼ huylu 105 doÄŸru, 4 yanlÄ±ÅŸ. YanlÄ±ÅŸ teÅŸhisler Ã§oÄŸunlukla "gÃ¼venli tarafta" - yani iyi huylu olanlarÄ± kÃ¶tÃ¼ huylu olarak teÅŸhis etmek.

**K deÄŸeri optimizasyonu**: K=1'den K=20'ye kadar test ettim. **K=9 en iyi performansÄ±** verdi.

<img width="621" height="468" alt="image" src="https://github.com/user-attachments/assets/cba76a63-f487-4bb5-b6c8-015b006f3a88" />


### Fonksiyon Tahmini
Distance weights daha dÃ¼zgÃ¼n sonuÃ§lar verdi. Uniform weights sert tahminler yaparken, distance weights gerÃ§ek fonksiyona Ã§ok daha yakÄ±n sonuÃ§lar Ã¼retti. GÃ¼rÃ¼ltÃ¼lÃ¼ verilerde bile KNN regresyonu iyi performans gÃ¶sterdi.

<img width="643" height="487" alt="Ekran gÃ¶rÃ¼ntÃ¼sÃ¼ 2025-09-29 184634" src="https://github.com/user-attachments/assets/61c3ba00-6509-406a-91f3-d4cb2030023e" />


## KÄ±sacasÄ±

KNN algoritmasÄ± basit ama etkili. En yakÄ±n K komÅŸuya bakÄ±p, Ã§oÄŸunluÄŸun sÄ±nÄ±fÄ±nÄ± tahmin ediyor.

**NasÄ±l Ã§alÄ±ÅŸÄ±r?** Yeni bir veri geldiÄŸinde, ona en yakÄ±n K tane komÅŸuyu buluyor. Bu komÅŸularÄ±n Ã§oÄŸunluÄŸu hangi sÄ±nÄ±ftaysa, yeni veri de o sÄ±nÄ±fa ait oluyor.

**Ã–nemli detaylar**: Ã–klid mesafesi kullanÄ±yor. K deÄŸeri kritik - Ã§ok kÃ¼Ã§Ã¼kse gÃ¼rÃ¼ltÃ¼ye hassas, Ã§ok bÃ¼yÃ¼kse detaylarÄ± kaÃ§Ä±rÄ±yor.

**Parametreler**: 
- n_neighbors (K) - kaÃ§ komÅŸuya bakacaÄŸÄ±m
- Weights - komÅŸularÄ± nasÄ±l aÄŸÄ±rlÄ±klandÄ±racaÄŸÄ±m (eÅŸit/mesafeye gÃ¶re)
- Metric - mesafeyi nasÄ±l hesaplayacaÄŸÄ±m

**Veri hazÄ±rlÄ±ÄŸÄ±**: StandardScaler Ã§ok Ã¶nemli. Train-test split ile modelin ezberleyip ezberlemediÄŸini test ettim.

